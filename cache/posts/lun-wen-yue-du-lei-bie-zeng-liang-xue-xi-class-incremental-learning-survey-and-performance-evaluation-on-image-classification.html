<div class="toc">
<ul>
<li><a href="#_1">简介</a></li>
<li><a href="#_2">一些常见概念</a><ul>
<li><a href="#task-il-vs-class-il">task-IL vs class-IL</a></li>
<li><a href="#sil-vs-cil-vs-fil">SIL vs CIL vs FIL</a></li>
</ul>
</li>
<li><a href="#_3">问题</a></li>
<li><a href="#_4">方法</a></li>
</ul>
</div>
<blockquote>
<p>基于增量学习的恶意代码家族分类
为什么用增量学习 + 恶意代码家族分类?
恶意代码家族分类是需要增量学习的典型任务场景, 恶意代码家族不可能预先给定, 不同的恶意代码家族会随着发展不断产生变体, 而在所有数据集上重新训练模型也是难以实现的, 是典型的class-incremental learning场景
其次, BODMAS数据集中包含500多个恶意代码家族, 为研究增量学习提供了可能性
再其次, 增量学习目前发展较慢, 仍存在大量问题, 通过增量学习实现恶意代码家族分类是有意义的, 而针对恶意代码家族分类去研究增量学习也是有意义的</p>
</blockquote>
<h2 id="_1">简介</h2>
<p>In most incremental learning scenarios, tasks are presented to a learner in a sequence of delineated <em>training sessions</em> during which data from a single task is available for learning.
After each training session, the learner should be capable of performing all perviously seen tasks on unseen data.</p>
<blockquote>
<p>在增量学习场景下, 每一轮训练针对一个任务进行训练, 在训练结束后, 要求模型能对前面训练过的所有任务进行完成</p>
</blockquote>
<p>The main challenge in incremental learning is to learn from data from the current task in a way that prevents forgetting of previously learned tasks.</p>
<blockquote>
<p>增量学习的主要问题就是避免当前训练对以前任务的遗忘</p>
</blockquote>
<p>这一点和迁移学习类似但也有所不同, 迁移学习不要求对以前训练任务的知识实现保留</p>
<p>They aim to exploit knowledge from previous classes to improve learning of new ones(<em>forward transfer</em>), as well as exploiting new data to improve performance on previous tasks(<em>backward transfer</em>)</p>
<blockquote>
<p>用旧知识帮助学习新知识, 用新知识巩固旧知识, sounds make sense</p>
</blockquote>
<h2 id="_2">一些常见概念</h2>
<h3 id="task-il-vs-class-il">task-IL vs class-IL</h3>
<p>task-IL: task-incremental learning, 在inference的时候, 会给定样本的task ID</p>
<p>class-IL: class-incremental learning, 在inference的时候, 不给定样本的task ID</p>
<p>这里还是有些不清楚</p>
<h3 id="sil-vs-cil-vs-fil">SIL vs CIL vs FIL</h3>
<ol>
<li>SIL</li>
</ol>
<p>问题：由于新数据的各种原因，样本的特征值可能会改变，每个类别的比例也会改变。这些都会影响分类的准确率。</p>
<p>任务：因此，需要确保在现有知识的情况下，通过新样本的增量学习来提取新知识，融合新旧知识以提高分类的准确性。</p>
<ol>
<li>
<p>CIL
任务：识别新类，并将其加入现有类别的集合中，提升分类的准确性和智能。</p>
</li>
<li>
<p>FIL
一些新的属性特征能够将分类提升到一个很大的程度，并提升分类准确率。</p>
</li>
</ol>
<p>任务：在现有特征空间的基础上，加入新的属性特征，构建新的特征空间，提升分类准确率。</p>
<h2 id="_3">问题</h2>
<p>catastrophic forgetting(灾难性遗忘), 为了克服灾难性遗忘, 我们一方面希望模型能从新数据中有效学习新知识, 但另一方面又必须防止新输入的数据对已有知识的显著干扰(稳定性), 即<strong>稳定性-可塑性困境</strong>(stability-plasticity dilemma)</p>
<p>增量学习的主要研究目的就是在计算和存储资源有限的条件下, 在稳定性-可塑性困境中寻找最佳平衡点</p>
<h2 id="_4">方法</h2>
<ol>
<li>
<p>正则(regularization)</p>
</li>
<li>
<p>回放(rehearsal)</p>
</li>
<li>
<p>参数隔离(parameter isolation)</p>
</li>
</ol>